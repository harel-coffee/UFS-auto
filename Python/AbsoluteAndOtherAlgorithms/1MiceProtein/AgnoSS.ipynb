{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf =tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#tf.set_random_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Activation, Dropout, Layer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers,initializers,constraints,regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import LambdaCallback,ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"./Defined\")\n",
    "import Functions as F\n",
    "\n",
    "# The following code should be added before the keras model\n",
    "#np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_lambda=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=pd.read_excel('./Dataset/Data_Cortex_Nuclear.xls',sheet_name='Hoja1')\n",
    "\n",
    "data_arr=(np.array(data_frame)[:,1:78]).copy()\n",
    "label_arr=(np.array(data_frame)[:,81]).copy()\n",
    "\n",
    "for index_i in np.arange(len(label_arr)):\n",
    "    if label_arr[index_i]=='c-CS-s':\n",
    "        label_arr[index_i]='0'\n",
    "    if label_arr[index_i]=='c-CS-m':\n",
    "        label_arr[index_i]='1'\n",
    "    if label_arr[index_i]=='c-SC-s':\n",
    "        label_arr[index_i]='2'\n",
    "    if label_arr[index_i]=='c-SC-m':\n",
    "        label_arr[index_i]='3'\n",
    "    if label_arr[index_i]=='t-CS-s':\n",
    "        label_arr[index_i]='4'\n",
    "    if label_arr[index_i]=='t-CS-m':\n",
    "        label_arr[index_i]='5'\n",
    "    if label_arr[index_i]=='t-SC-s':\n",
    "        label_arr[index_i]='6'\n",
    "    if label_arr[index_i]=='t-SC-m':\n",
    "        label_arr[index_i]='7'\n",
    "\n",
    "label_arr_onehot=label_arr#to_categorical(label_arr)\n",
    "# Show before Imputer\n",
    "#print(data_arr[558])\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(data_arr)\n",
    "data_arr=imp_mean.transform(data_arr)\n",
    "\n",
    "# Show after Imputer\n",
    "#print(data_arr[558])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr=MinMaxScaler(feature_range=(0,1)).fit_transform(data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (777, 77)\n",
      "Shape of x_validate: (87, 77)\n",
      "Shape of x_test: (216, 77)\n",
      "Shape of y_train: (777,)\n",
      "Shape of y_validate: (87,)\n",
      "Shape of y_test: (216,)\n",
      "Shape of C_train_x: (864, 77)\n",
      "Shape of C_train_y: (864,)\n",
      "Shape of C_test_x: (216, 77)\n",
      "Shape of C_test_y: (216,)\n"
     ]
    }
   ],
   "source": [
    "C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(data_arr,label_arr_onehot,test_size=0.2,random_state=seed)\n",
    "x_train,x_validate,y_train_onehot,y_validate_onehot= train_test_split(C_train_x,C_train_y,test_size=0.1,random_state=seed)\n",
    "x_test=C_test_x\n",
    "y_test_onehot=C_test_y\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape)) \n",
    "print('Shape of x_validate: ' + str(x_validate.shape)) \n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train_onehot.shape))\n",
    "print('Shape of y_validate: ' + str(y_validate_onehot.shape))\n",
    "print('Shape of y_test: ' + str(y_test_onehot.shape))\n",
    "\n",
    "print('Shape of C_train_x: ' + str(C_train_x.shape)) \n",
    "print('Shape of C_train_y: ' + str(C_train_y.shape)) \n",
    "print('Shape of C_test_x: ' + str(C_test_x.shape)) \n",
    "print('Shape of C_test_y: ' + str(C_test_y.shape)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "class Feature_Select_Layer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, l1_lambda, **kwargs):\n",
    "        super(Feature_Select_Layer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.l1_lambda=l1_lambda\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',  \n",
    "                                      shape=(input_shape[1],),\n",
    "                                      initializer=initializers.RandomUniform(minval=0., maxval=1.),\n",
    "                                      trainable=True,\n",
    "                                      regularizer=regularizers.l1(self.l1_lambda),\n",
    "                                      constraint=constraints.NonNeg())\n",
    "        super(Feature_Select_Layer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x, selection=False,k=36):\n",
    "        kernel=self.kernel        \n",
    "        if selection:\n",
    "            kernel_=K.transpose(kernel)\n",
    "            print(kernel_.shape)\n",
    "            kth_largest = tf.math.top_k(kernel_, k=k)[0][-1]\n",
    "            kernel = tf.where(condition=K.less(kernel,kth_largest),x=K.zeros_like(kernel),y=kernel)        \n",
    "        return K.dot(x, tf.linalg.tensor_diag(kernel))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Identity_Autoencoder(p_data_feature=x_train.shape[1],\\\n",
    "                         p_encoding_dim=50,\\\n",
    "                         p_learning_rate= 1E-3,\\\n",
    "                         p_l1_lambda=0.1):\n",
    "    \n",
    "    input_img = Input(shape=(p_data_feature,), name='autoencoder_input')\n",
    "\n",
    "    feature_selection = Feature_Select_Layer(output_dim=p_data_feature,\\\n",
    "                                             l1_lambda=p_l1_lambda,\\\n",
    "                                             input_shape=(p_data_feature,),\\\n",
    "                                             name='feature_selection')\n",
    "\n",
    "    feature_selection_score=feature_selection(input_img)\n",
    "\n",
    "    encoded = Dense(p_encoding_dim,\\\n",
    "                    activation='tanh',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_hidden_layer')\n",
    "    \n",
    "    encoded_score=encoded(feature_selection_score)\n",
    "    \n",
    "    bottleneck_score=encoded_score\n",
    "    \n",
    "    decoded = Dense(p_data_feature,\\\n",
    "                    activation='tanh',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_output')\n",
    "    \n",
    "    decoded_score =decoded(bottleneck_score)\n",
    "\n",
    "    latent_encoder_score = Model(input_img, bottleneck_score)\n",
    "    autoencoder = Model(input_img, decoded_score)\n",
    "    \n",
    "    autoencoder.compile(loss='mean_squared_error',\\\n",
    "                        optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder,latent_encoder_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=1000\n",
    "batch_size_value=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1.1 Identity Autoencoder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Autoencoder Structure-------------------------------------\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_input (InputLaye (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "feature_selection (Feature_S (None, 77)                77        \n",
      "_________________________________________________________________\n",
      "autoencoder_hidden_layer (De (None, 10)                780       \n",
      "_________________________________________________________________\n",
      "autoencoder_output (Dense)   (None, 77)                847       \n",
      "=================================================================\n",
      "Total params: 1,704\n",
      "Trainable params: 1,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ide_AE,\\\n",
    "latent_encoder_score_Ide_AE=Identity_Autoencoder(p_data_feature=x_train.shape[1],\\\n",
    "                                                 p_encoding_dim=10,\\\n",
    "                                                 p_learning_rate= 1E-2,\\\n",
    "                                                 p_l1_lambda=l1_lambda)\n",
    "\n",
    "file_name=\"./log/AgnoSS.png\"\n",
    "plot_model(Ide_AE, to_file=file_name,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 777 samples, validate on 87 samples\n",
      "Epoch 1/1000\n",
      "777/777 [==============================] - 0s 420us/step - loss: 36.3064 - val_loss: 33.0983\n",
      "Epoch 2/1000\n",
      "777/777 [==============================] - 0s 22us/step - loss: 31.2489 - val_loss: 28.0596\n",
      "Epoch 3/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 26.3345 - val_loss: 23.4379\n",
      "Epoch 4/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 21.8889 - val_loss: 19.2462\n",
      "Epoch 5/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 17.7955 - val_loss: 15.3882\n",
      "Epoch 6/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 14.0863 - val_loss: 11.8829\n",
      "Epoch 7/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 10.7905 - val_loss: 8.9744\n",
      "Epoch 8/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 8.0216 - val_loss: 6.4660\n",
      "Epoch 9/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 5.6789 - val_loss: 4.4023\n",
      "Epoch 10/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 3.7468 - val_loss: 2.6868\n",
      "Epoch 11/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 2.2238 - val_loss: 1.5722\n",
      "Epoch 12/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 1.2809 - val_loss: 0.7994\n",
      "Epoch 13/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.6099 - val_loss: 0.3070\n",
      "Epoch 14/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.1888 - val_loss: 0.0394\n",
      "Epoch 15/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0235 - val_loss: 0.0198\n",
      "Epoch 16/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 17/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 18/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 19/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 20/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 21/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 22/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 23/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 24/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 25/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 26/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 27/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 28/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 29/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 30/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 31/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 32/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 33/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 34/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 35/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 36/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 37/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 38/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 39/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 40/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 41/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 42/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 43/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 44/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 45/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 46/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 47/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 48/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 49/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 50/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 51/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 52/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 53/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 54/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 55/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 56/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 57/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 58/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 59/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 60/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 61/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 62/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 63/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 64/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 65/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 66/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 67/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 68/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 69/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 70/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 71/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 72/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 73/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 74/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 75/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 76/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 77/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 78/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 79/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 80/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 81/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 82/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 83/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 84/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 85/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 86/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 87/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 88/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 89/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 90/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 91/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 92/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 93/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 94/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 95/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 96/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 97/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 98/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 99/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 100/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00100: saving model to ./log_weights/Ide_AE_weights.0100.hdf5\n",
      "Epoch 101/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 102/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 103/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 104/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 105/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 106/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 107/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 108/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 109/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 110/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 111/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 112/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 113/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 114/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 115/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 116/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 117/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 118/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 119/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 120/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 121/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 122/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 123/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 124/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 125/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 126/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 127/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 128/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 129/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 130/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 131/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 132/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 133/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 134/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 135/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 136/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 137/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 138/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 139/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 140/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 141/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 142/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 143/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 144/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0201\n",
      "Epoch 145/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 146/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 147/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 148/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 149/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 150/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 151/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 152/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 153/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 154/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 155/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 156/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 157/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 158/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 159/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 160/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 161/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 162/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 163/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 164/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 165/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 166/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 167/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 168/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 169/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 170/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 171/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 172/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 173/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 174/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 175/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 176/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 177/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 178/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 179/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 180/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 181/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 182/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 183/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 184/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 185/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 186/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 187/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 188/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 189/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 190/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 191/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 192/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 193/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 194/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 195/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 196/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 197/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 198/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 199/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 200/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00200: saving model to ./log_weights/Ide_AE_weights.0200.hdf5\n",
      "Epoch 201/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 202/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 203/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 204/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 205/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 206/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 207/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 208/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 209/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 210/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 211/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 212/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 213/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 214/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 215/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 216/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 217/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 218/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 219/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 220/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 221/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 222/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 223/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 224/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 225/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 226/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 227/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 228/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 229/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 230/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 231/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 232/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 233/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 234/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 235/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 236/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 237/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 238/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 239/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 240/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 241/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 242/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 243/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 244/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 245/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 246/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 247/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 248/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 249/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 250/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 251/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 252/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 253/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 254/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 255/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 256/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 257/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 258/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 259/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 260/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 261/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 262/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 263/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 264/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 265/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 266/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 267/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 268/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 269/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 270/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 271/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 272/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 273/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 274/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 275/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0201\n",
      "Epoch 276/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 277/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 278/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 279/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 280/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 281/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 282/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 283/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 284/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 285/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 286/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 287/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 288/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 289/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 290/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 291/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 292/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 293/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 294/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 295/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 296/1000\n",
      "777/777 [==============================] - ETA: 0s - loss: 0.020 - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 297/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 298/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 299/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 300/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00300: saving model to ./log_weights/Ide_AE_weights.0300.hdf5\n",
      "Epoch 301/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 302/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 303/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 304/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 305/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 306/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 307/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 308/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 309/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 310/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 311/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 312/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 313/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 314/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 315/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 316/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 317/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 318/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 319/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 320/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 321/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 322/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 323/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 324/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 325/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 326/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 327/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 328/1000\n",
      "777/777 [==============================] - 0s 47us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 329/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 330/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 331/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 332/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 333/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 334/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 335/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 336/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 337/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 338/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 339/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 340/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 341/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 342/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 343/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 344/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 345/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 346/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 347/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 348/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 349/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 350/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 351/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 352/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 353/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 354/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 355/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 356/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 357/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 358/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 359/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 360/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 361/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 362/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 363/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 364/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 365/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 366/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 367/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 368/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 369/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 370/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 371/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 372/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 373/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 374/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 375/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 376/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 377/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 378/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 379/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 380/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 381/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 382/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 383/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 384/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 385/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 386/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 387/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 388/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 389/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 390/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 391/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 392/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 393/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 394/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 395/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 396/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 397/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 398/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 399/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 400/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00400: saving model to ./log_weights/Ide_AE_weights.0400.hdf5\n",
      "Epoch 401/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 402/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 403/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 404/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 405/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 406/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 407/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 408/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 409/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 410/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 411/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 412/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 413/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 414/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 415/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 416/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 417/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 418/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 419/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 420/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 421/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 422/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 423/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 424/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 425/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 426/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 427/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 428/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 429/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 430/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 431/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 432/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 433/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 434/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 435/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 436/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 437/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 438/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 439/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 440/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 441/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 442/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 443/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 444/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 445/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 446/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 447/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 448/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 449/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 450/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 451/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 452/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 453/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 454/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 455/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 456/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 457/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 458/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 459/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 460/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 461/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 462/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 463/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 464/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 465/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 466/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 467/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 468/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 469/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 470/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 471/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 472/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 473/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 474/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 475/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 476/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 477/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 478/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 479/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 480/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 481/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 482/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 483/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 484/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 485/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 486/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 487/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 488/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 489/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 490/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 491/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 492/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 493/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 494/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 495/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 496/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 497/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 498/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 499/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 500/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00500: saving model to ./log_weights/Ide_AE_weights.0500.hdf5\n",
      "Epoch 501/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 502/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 503/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 504/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 505/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 506/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 507/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 508/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 509/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 510/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 511/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 512/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 513/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 514/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 515/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 516/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 517/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 518/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 519/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 520/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 521/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 522/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 523/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 524/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 525/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 526/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 527/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 528/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 529/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 530/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 531/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 532/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 533/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 534/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 535/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 536/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 537/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 538/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 539/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 540/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 541/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 542/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 543/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 544/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 545/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 546/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 547/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 548/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 549/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 550/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 551/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 552/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 553/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 554/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 555/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 556/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 557/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 558/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 559/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 560/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 561/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 562/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 563/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 564/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 565/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 566/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 567/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 568/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 569/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 570/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 571/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 572/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 573/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 574/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 575/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 576/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 577/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 578/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 579/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 580/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 581/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 582/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 583/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 584/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 585/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 586/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 587/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 588/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 589/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 590/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 591/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 592/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 593/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 594/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 595/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 596/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 597/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 598/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 599/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 600/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00600: saving model to ./log_weights/Ide_AE_weights.0600.hdf5\n",
      "Epoch 601/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 602/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 603/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 604/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 605/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 606/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 607/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 608/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 609/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 610/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 611/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 612/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 613/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 614/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 615/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 616/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 617/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 618/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 619/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 620/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 621/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 622/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 623/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 624/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 625/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 626/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 627/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 628/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 629/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 630/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 631/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 632/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 633/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 634/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 635/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 636/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 637/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 638/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 639/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 640/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 641/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 642/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 643/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 644/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 645/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 646/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 647/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 648/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 649/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 650/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 651/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 652/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 653/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 654/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 655/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 656/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 657/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 658/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 659/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 660/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 661/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 662/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 663/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 664/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 665/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 666/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 667/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 668/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 669/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 670/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 671/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 672/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 673/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 674/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 675/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 676/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 677/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 678/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 679/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 680/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 681/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 682/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 683/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 684/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 685/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 686/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 687/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 688/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 689/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 690/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 691/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 692/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 693/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 694/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 695/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 696/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 697/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 698/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 699/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 700/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00700: saving model to ./log_weights/Ide_AE_weights.0700.hdf5\n",
      "Epoch 701/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 702/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 703/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 704/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 705/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 706/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 707/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 708/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 709/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 710/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 711/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 712/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 713/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 714/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 715/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 716/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 717/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 718/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 719/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 720/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 721/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 722/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 723/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 724/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 725/1000\n",
      "777/777 [==============================] - 0s 32us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 726/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 727/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 728/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 729/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 730/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 731/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 732/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 733/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 734/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 735/1000\n",
      "777/777 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 736/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 737/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 738/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 739/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 740/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 741/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 742/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 743/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 744/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 745/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 746/1000\n",
      "777/777 [==============================] - 0s 21us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 747/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 748/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 749/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 750/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 751/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 752/1000\n",
      "777/777 [==============================] - 0s 41us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 753/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 754/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 755/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 756/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 757/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 758/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 759/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 760/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 761/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 762/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 763/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 764/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 765/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 766/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 767/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 768/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 769/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 770/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 771/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 772/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 773/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 774/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 775/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 776/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 777/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 778/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 779/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 780/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 781/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 782/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 783/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 784/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 785/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 786/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 787/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 788/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 789/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 790/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 791/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 792/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 793/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 794/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 795/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 796/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 797/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 798/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 799/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 800/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00800: saving model to ./log_weights/Ide_AE_weights.0800.hdf5\n",
      "Epoch 801/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 802/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 803/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 804/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 805/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 806/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 807/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 808/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 809/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 810/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 811/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 812/1000\n",
      "777/777 [==============================] - 0s 30us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 813/1000\n",
      "777/777 [==============================] - 0s 28us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 814/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 815/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 816/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 817/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 818/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 819/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 820/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 821/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 822/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 823/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 824/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 825/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 826/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 827/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 828/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 829/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 830/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 831/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 832/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 833/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 834/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 835/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 836/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 837/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 838/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 839/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 840/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 841/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 842/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 843/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 844/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 845/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 846/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 847/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 848/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 849/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 850/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 851/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 852/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 853/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 854/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 855/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 856/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 857/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 858/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 859/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 860/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 861/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 862/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 863/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 864/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 865/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 866/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 867/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 868/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 869/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 870/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 871/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 872/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 873/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 874/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 875/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 876/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 877/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 878/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 879/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 880/1000\n",
      "777/777 [==============================] - 0s 46us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 881/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 882/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 883/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 884/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 885/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 886/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 887/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 888/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 889/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 890/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 891/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 892/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 893/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 894/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 895/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 896/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 897/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 898/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 899/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 900/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "\n",
      "Epoch 00900: saving model to ./log_weights/Ide_AE_weights.0900.hdf5\n",
      "Epoch 901/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 902/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 903/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 904/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 905/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 906/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 907/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 908/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 909/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 910/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 911/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 912/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 913/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 914/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 915/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 916/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 917/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 918/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 919/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 920/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 921/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 922/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 923/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 924/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 925/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 926/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 927/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 928/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 929/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 930/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 931/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 932/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 933/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 934/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 935/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 936/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 937/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 938/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 939/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 940/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 941/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 942/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 943/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 944/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 945/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 946/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 947/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 948/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 949/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 950/1000\n",
      "777/777 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 951/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 952/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 953/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 954/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 955/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 956/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 957/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 958/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 959/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 960/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 961/1000\n",
      "777/777 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 962/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 963/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 964/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 965/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 966/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 967/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 968/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 969/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 970/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 971/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 972/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 973/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 974/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 975/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 976/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 977/1000\n",
      "777/777 [==============================] - 0s 23us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 978/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 979/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 980/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 981/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 982/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 983/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 984/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 985/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 986/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 987/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 988/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 989/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 990/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 991/1000\n",
      "777/777 [==============================] - 0s 24us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 992/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 993/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 994/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 995/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 996/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 997/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 998/1000\n",
      "777/777 [==============================] - 0s 26us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 999/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 1000/1000\n",
      "777/777 [==============================] - 0s 25us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "\n",
      "Epoch 01000: saving model to ./log_weights/Ide_AE_weights.1000.hdf5\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint=ModelCheckpoint('./log_weights/Ide_AE_weights.{epoch:04d}.hdf5',period=100,save_weights_only=True,verbose=1)\n",
    "#print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(Ide_AE.layers[1].get_weights()))\n",
    "\n",
    "Ide_AE_history = Ide_AE.fit(x_train, x_train,\\\n",
    "                            epochs=epochs_number,\\\n",
    "                            batch_size=batch_size_value,\\\n",
    "                            shuffle=True,\\\n",
    "                            validation_data=(x_validate,x_validate),\\\n",
    "                            callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = Ide_AE_history.history['loss']\n",
    "val_loss = Ide_AE_history.history['val_loss']\n",
    "\n",
    "epochs = range(epochs_number)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for one-to-one map layer 0.02016874912274216\n"
     ]
    }
   ],
   "source": [
    "p_data=Ide_AE.predict(x_test)\n",
    "numbers=x_test.shape[0]*x_test.shape[1]\n",
    "\n",
    "print(\"MSE for one-to-one map layer\",np.sum(np.power(np.array(p_data)-x_test,2))/numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "key_number=10\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_number=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features=F.top_k_keepWeights_1(Ide_AE.get_layer(index=1).get_weights()[0],key_number)\n",
    "\n",
    "selected_position_list=np.where(key_features>0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n"
     ]
    }
   ],
   "source": [
    "train_feature=C_train_x\n",
    "train_label=C_train_y\n",
    "test_feature=C_test_x\n",
    "test_label=C_test_y\n",
    "p_seed=seed\n",
    "F.ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864, 4)\n",
      "(216, 4)\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.5185185185185185\n",
      "Testing accuracy： 0.5185185185185185\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature_=np.multiply(C_train_x, key_features)\n",
    "train_feature=F.compress_zero_withkeystructure(train_feature_,selected_position_list)\n",
    "print(train_feature.shape)\n",
    "train_label=C_train_y\n",
    "\n",
    "test_feature_=np.multiply(C_test_x, key_features)\n",
    "test_feature=F.compress_zero_withkeystructure(test_feature_,selected_position_list)\n",
    "print(test_feature.shape)\n",
    "test_label=C_test_y\n",
    "\n",
    "p_seed=seed\n",
    "F.ETree(train_feature,train_label,test_feature,test_label,p_seed)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864, 4)\n",
      "(216, 4)\n",
      "0.01283562218318222\n"
     ]
    }
   ],
   "source": [
    "train_feature_=np.multiply(C_train_x, key_features)\n",
    "C_train_selected_x=F.compress_zero_withkeystructure(train_feature_,selected_position_list)\n",
    "print(C_train_selected_x.shape)\n",
    "\n",
    "test_feature_=np.multiply(C_test_x, key_features)\n",
    "C_test_selected_x=F.compress_zero_withkeystructure(test_feature_,selected_position_list)\n",
    "print(C_test_selected_x.shape)\n",
    "\n",
    "\n",
    "train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
