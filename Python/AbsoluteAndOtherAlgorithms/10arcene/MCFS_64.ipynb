{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.io\n",
    "from skfeature.function.sparse_learning_based import MCFS\n",
    "from skfeature.utility import construct_W\n",
    "\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def ETree(p_train_feature,p_train_label,p_test_feature,p_test_label,p_seed):\n",
    "    clf = ExtraTreesClassifier(n_estimators=50, random_state=p_seed)\n",
    "    \n",
    "    # Training\n",
    "    clf.fit(p_train_feature, p_train_label)\n",
    "    \n",
    "    # Training accuracy\n",
    "    print('Training accuracy：',clf.score(p_train_feature, np.array(p_train_label)))\n",
    "    print('Training accuracy：',accuracy_score(np.array(p_train_label),clf.predict(p_train_feature)))\n",
    "    #print('Training accuracy：',np.sum(clf.predict(p_train_feature)==np.array(p_train_label))/p_train_label.shape[0])\n",
    "\n",
    "    # Testing accuracy\n",
    "    print('Testing accuracy：',clf.score(p_test_feature, np.array(p_test_label)))\n",
    "    print('Testing accuracy：',accuracy_score(np.array(p_test_label),clf.predict(p_test_feature)))\n",
    "    #print('Testing accuracy：',np.sum(clf.predict(p_test_feature)==np.array(p_test_label))/p_test_label.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of C_train_x: (160, 10000)\n",
      "Shape of C_train_y: (160,)\n",
      "Shape of C_test_x: (40, 10000)\n",
      "Shape of C_test_y: (40,)\n"
     ]
    }
   ],
   "source": [
    "data_path=\"./Dataset/arcene.mat\"\n",
    "Data = scipy.io.loadmat(data_path)\n",
    "\n",
    "data_arr=Data['X']\n",
    "label_arr_=Data['Y'][:, 0]\n",
    "\n",
    "label_arr=np.array([0 if label_arr_i<0 else label_arr_i for label_arr_i in label_arr_])\n",
    "\n",
    "data_arr=MinMaxScaler(feature_range=(0,1)).fit_transform(data_arr)\n",
    "\n",
    "C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(data_arr,label_arr,test_size=0.2,random_state=seed)\n",
    "\n",
    "print('Shape of C_train_x: ' + str(C_train_x.shape)) \n",
    "print('Shape of C_train_y: ' + str(C_train_y.shape)) \n",
    "print('Shape of C_test_x: ' + str(C_test_x.shape)) \n",
    "print('Shape of C_test_y: ' + str(C_test_y.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifying 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_feature: (160, 10000)\n",
      "Shape of train_label: (160,)\n",
      "Shape of test_feature: (40, 10000)\n",
      "Shape of test_label: (40,)\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.85\n",
      "Testing accuracy： 0.85\n"
     ]
    }
   ],
   "source": [
    "train_feature=C_train_x\n",
    "train_label=C_train_y\n",
    "test_feature=C_test_x\n",
    "test_label=C_test_y\n",
    "\n",
    "print('Shape of train_feature: ' + str(train_feature.shape)) \n",
    "print('Shape of train_label: ' + str(train_label.shape)) \n",
    "print('Shape of test_feature: ' + str(test_feature.shape)) \n",
    "print('Shape of test_label: ' + str(test_label.shape)) \n",
    "\n",
    "p_seed=seed\n",
    "ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cluster=len(np.unique(label_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_selected_x (160, 64)\n",
      "Data_selected_x (40, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:30: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# construct affinity matrix\n",
    "kwargs_W =  {\"metric\": \"euclidean\", \"neighborMode\": \"knn\", \"weightMode\": \"heatKernel\", \"k\": 5, 't': 1}\n",
    "\n",
    "train_W = construct_W.construct_W(train_feature, **kwargs_W)\n",
    "\n",
    "# obtain the scores of features, and sort the feature scores in an ascending order according to the feature scores\n",
    "tain_score = MCFS.mcfs(train_feature, n_selected_features=key_feture_number, W=train_W,n_clusters=num_cluster)\n",
    "train_idx = MCFS.feature_ranking(tain_score)\n",
    "\n",
    "# obtain the dataset on the selected features\n",
    "train_selected_x = train_feature[:, train_idx[0:key_feture_number]]\n",
    "\n",
    "print(\"train_selected_x\",train_selected_x.shape)\n",
    "\n",
    "\n",
    "test_W = construct_W.construct_W(test_feature, **kwargs_W)\n",
    "\n",
    "# obtain the scores of features, and sort the feature scores in an ascending order according to the feature scores\n",
    "test_score = MCFS.mcfs(test_feature, n_selected_features=key_feture_number, W=test_W,n_clusters=num_cluster)\n",
    "test_idx = MCFS.feature_ranking(test_score)\n",
    "\n",
    "# obtain the dataset on the selected features\n",
    "test_selected_x = test_feature[:, test_idx[0:key_feture_number]]\n",
    "\n",
    "print(\"Data_selected_x\",test_selected_x.shape)\n",
    "\n",
    "\n",
    "time_cost=time.clock() - start\n",
    "\n",
    "write_to_csv(np.array([time_cost]),\"./log/MCFS_time\"+str(key_feture_number)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classifying 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_feature: (160, 64)\n",
      "Shape of train_label: (160,)\n",
      "Shape of test_feature: (40, 64)\n",
      "Shape of test_label: (40,)\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.625\n",
      "Testing accuracy： 0.625\n"
     ]
    }
   ],
   "source": [
    "train_feature=train_selected_x\n",
    "train_label=C_train_y\n",
    "\n",
    "test_feature=test_selected_x\n",
    "test_label=C_test_y\n",
    "\n",
    "print('Shape of train_feature: ' + str(train_feature.shape)) \n",
    "print('Shape of train_label: ' + str(train_label.shape)) \n",
    "print('Shape of test_feature: ' + str(test_feature.shape)) \n",
    "print('Shape of test_label: ' + str(test_label.shape)) \n",
    "\n",
    "p_seed=seed\n",
    "ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.826201016478801\n"
     ]
    }
   ],
   "source": [
    "train_feature_tuple=(train_selected_x,C_train_x)\n",
    "test_feature_tuple=(test_selected_x,C_test_x)\n",
    "\n",
    "reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
