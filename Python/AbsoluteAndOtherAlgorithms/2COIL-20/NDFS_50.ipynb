{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.io\n",
    "from skfeature.function.sparse_learning_based import NDFS\n",
    "from skfeature.utility import construct_W\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def ETree(p_train_feature,p_train_label,p_test_feature,p_test_label,p_seed):\n",
    "    clf = ExtraTreesClassifier(n_estimators=50, random_state=p_seed)\n",
    "    \n",
    "    # Training\n",
    "    clf.fit(p_train_feature, p_train_label)\n",
    "    \n",
    "    # Training accuracy\n",
    "    print('Training accuracy：',clf.score(p_train_feature, np.array(p_train_label)))\n",
    "    print('Training accuracy：',accuracy_score(np.array(p_train_label),clf.predict(p_train_feature)))\n",
    "    #print('Training accuracy：',np.sum(clf.predict(p_train_feature)==np.array(p_train_label))/p_train_label.shape[0])\n",
    "\n",
    "    # Testing accuracy\n",
    "    print('Testing accuracy：',clf.score(p_test_feature, np.array(p_test_label)))\n",
    "    print('Testing accuracy：',accuracy_score(np.array(p_test_label),clf.predict(p_test_feature)))\n",
    "    #print('Testing accuracy：',np.sum(clf.predict(p_test_feature)==np.array(p_test_label))/p_test_label.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path='./Dataset/COIL-20/'\n",
    "\n",
    "samples={}\n",
    "for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
    "    #print(dirpath)\n",
    "    #print(dirnames)\n",
    "    #print(filenames)\n",
    "    dirnames.sort()\n",
    "    filenames.sort()\n",
    "    for filename in [f for f in filenames if f.endswith(\".png\") and not f.find('checkpoint')>0]:\n",
    "        full_path = os.path.join(dirpath, filename)\n",
    "        file_identifier=filename.split('__')[0][3:]\n",
    "        if file_identifier not in samples.keys():\n",
    "            samples[file_identifier] = []\n",
    "        # Direct read\n",
    "        #image = io.imread(full_path)\n",
    "        # Resize read\n",
    "        image_=Image.open(full_path).resize((20, 20),Image.ANTIALIAS)\n",
    "        image=np.asarray(image_)\n",
    "        samples[file_identifier].append(image)\n",
    "        \n",
    "#plt.imshow(samples['1'][0].reshape(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr_list=[]\n",
    "label_arr_list=[]\n",
    "for key_i in samples.keys():\n",
    "    key_i_for_label=[int(key_i)-1]\n",
    "    data_arr_list.append(np.array(samples[key_i]))\n",
    "    label_arr_list.append(np.array(72*key_i_for_label))\n",
    "    \n",
    "data_arr=np.concatenate(data_arr_list).reshape(1440, 20*20).astype('float32') / 255.\n",
    "label_arr_onehot=np.concatenate(label_arr_list)#to_categorical(np.concatenate(label_arr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (1036, 400)\n",
      "Shape of x_validate: (116, 400)\n",
      "Shape of x_test: (288, 400)\n",
      "Shape of y_train: (1036,)\n",
      "Shape of y_validate: (116,)\n",
      "Shape of y_test: (288,)\n",
      "Shape of C_train_x: (1152, 400)\n",
      "Shape of C_train_y: (1152,)\n",
      "Shape of C_test_x: (288, 400)\n",
      "Shape of C_test_y: (288,)\n"
     ]
    }
   ],
   "source": [
    "C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(data_arr,label_arr_onehot,test_size=0.2,random_state=seed)\n",
    "x_train,x_validate,y_train_onehot,y_validate_onehot= train_test_split(C_train_x,C_train_y,test_size=0.1,random_state=seed)\n",
    "x_test=C_test_x\n",
    "y_test_onehot=C_test_y\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape)) \n",
    "print('Shape of x_validate: ' + str(x_validate.shape)) \n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train_onehot.shape))\n",
    "print('Shape of y_validate: ' + str(y_validate_onehot.shape))\n",
    "print('Shape of y_test: ' + str(y_test_onehot.shape))\n",
    "\n",
    "print('Shape of C_train_x: ' + str(C_train_x.shape)) \n",
    "print('Shape of C_train_y: ' + str(C_train_y.shape)) \n",
    "print('Shape of C_test_x: ' + str(C_test_x.shape)) \n",
    "print('Shape of C_test_y: ' + str(C_test_y.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifying 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_feature: (1152, 400)\n",
      "Shape of train_label: (1152,)\n",
      "Shape of test_feature: (288, 400)\n",
      "Shape of test_label: (288,)\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n"
     ]
    }
   ],
   "source": [
    "train_feature=C_train_x\n",
    "train_label=C_train_y\n",
    "test_feature=C_test_x\n",
    "test_label=C_test_y\n",
    "\n",
    "print('Shape of train_feature: ' + str(train_feature.shape)) \n",
    "print('Shape of train_label: ' + str(train_label.shape)) \n",
    "print('Shape of test_feature: ' + str(test_feature.shape)) \n",
    "print('Shape of test_label: ' + str(test_label.shape)) \n",
    "\n",
    "p_seed=seed\n",
    "ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cluster=len(np.unique(C_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:934: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  \"effect\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:939: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  \" removed in 0.25.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_selected_x (1152, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:934: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  \"effect\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py:939: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  \" removed in 0.25.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_selected_x (288, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# construct affinity matrix\n",
    "kwargs_W =  {\"metric\": \"euclidean\", \"neighborMode\": \"knn\", \"weightMode\": \"heatKernel\", \"k\": 5, 't': 1}\n",
    "\n",
    "train_W = construct_W.construct_W(train_feature, **kwargs_W)\n",
    "\n",
    "# obtain the scores of features, and sort the feature scores in an ascending order according to the feature scores\n",
    "train_score = NDFS.ndfs(train_feature, W=train_W,n_clusters=num_cluster)\n",
    "\n",
    "train_idx = feature_ranking(train_score)\n",
    "\n",
    "# obtain the dataset on the selected features\n",
    "train_selected_x = train_feature[:, train_idx[0:key_feture_number]]\n",
    "print(\"train_selected_x\",train_selected_x.shape)\n",
    "\n",
    "\n",
    "test_W = construct_W.construct_W(test_feature, **kwargs_W)\n",
    "\n",
    "# obtain the scores of features, and sort the feature scores in an ascending order according to the feature scores\n",
    "test_score = NDFS.ndfs(test_feature, W=test_W,n_clusters=num_cluster)\n",
    "\n",
    "test_idx = feature_ranking(test_score)\n",
    "\n",
    "# obtain the dataset on the selected features\n",
    "test_selected_x = test_feature[:, test_idx[0:key_feture_number]]\n",
    "print(\"test_selected_x\",test_selected_x.shape)\n",
    "\n",
    "\n",
    "\n",
    "time_cost=time.clock() - start\n",
    "\n",
    "write_to_csv(np.array([time_cost]),\"./log/NDFS_time\"+str(key_feture_number)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classifying 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_feature: (1152, 50)\n",
      "Shape of train_label: (1152,)\n",
      "Shape of test_feature: (288, 50)\n",
      "Shape of test_label: (288,)\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.21180555555555555\n",
      "Testing accuracy： 0.21180555555555555\n"
     ]
    }
   ],
   "source": [
    "train_feature=train_selected_x\n",
    "train_label=C_train_y\n",
    "\n",
    "test_feature=test_selected_x\n",
    "test_label=C_test_y\n",
    "\n",
    "print('Shape of train_feature: ' + str(train_feature.shape)) \n",
    "print('Shape of train_label: ' + str(train_label.shape)) \n",
    "print('Shape of test_feature: ' + str(test_feature.shape)) \n",
    "print('Shape of test_label: ' + str(test_label.shape)) \n",
    "\n",
    "p_seed=seed\n",
    "ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13383722\n"
     ]
    }
   ],
   "source": [
    "train_feature_tuple=(train_selected_x,C_train_x)\n",
    "test_feature_tuple=(test_selected_x,C_test_x)\n",
    "\n",
    "reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
