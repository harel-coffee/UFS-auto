{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.function.similarity_based import lap_score\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.linalg import qr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_subset_selector(A, k):\n",
    "    eps = 1e-6\n",
    "    A_scaled = A / np.sqrt(np.sum(np.square(A), axis=0) / (A.shape[0] - 1))\n",
    "    u, d, v = np.linalg.svd(A_scaled)\n",
    "    u_, d_, v_ = np.linalg.svd(A, k)\n",
    "    n = np.where(d_ < eps)[0]\n",
    "    if(len(n)>0 and k > n[0]):\n",
    "        k = n[0] - 1\n",
    "        print(\"k was reduced to match the rank of A\")\n",
    "    Q, R, P = qr((v[:,:k]).T, pivoting=True)\n",
    "    indices = P[:k]\n",
    "    return indices\n",
    "\n",
    "def pfa_selector(A, k, debug = False):\n",
    "    class PFA(object):\n",
    "        def __init__(self, n_features, q=0.5):\n",
    "            self.q = q\n",
    "            self.n_features = n_features\n",
    "        \n",
    "        def fit(self, X):\n",
    "            if not self.q:\n",
    "                self.q = X.shape[1]\n",
    "\n",
    "            sc = StandardScaler()\n",
    "            X = sc.fit_transform(X)\n",
    "\n",
    "            pca = PCA(n_components=self.q).fit(X)\n",
    "            self.n_components_ = pca.n_components_\n",
    "            A_q = pca.components_.T\n",
    "\n",
    "            kmeans = KMeans(n_clusters=self.n_features).fit(A_q)\n",
    "            clusters = kmeans.predict(A_q)\n",
    "            cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "            self.indices_ = [] \n",
    "            for cluster_idx in range(self.n_features):\n",
    "                indices_in_cluster = np.where(clusters==cluster_idx)[0]\n",
    "                points_in_cluster = A_q[indices_in_cluster, :]\n",
    "                centroid = cluster_centers[cluster_idx]\n",
    "                distances = np.linalg.norm(points_in_cluster - centroid, axis=1)\n",
    "                optimal_index = indices_in_cluster[np.argmin(distances)]\n",
    "                self.indices_.append(optimal_index) \n",
    "  \n",
    "    pfa = PFA(n_features = k)\n",
    "    pfa.fit(A)\n",
    "    if debug:\n",
    "        print('Performed PFW with q=', pfa.n_components_)\n",
    "    column_indices = pfa.indices_\n",
    "    return column_indices\n",
    "\n",
    "def pfa_transform(A, B, k, debug = False):\n",
    "    indices = pfa_selector(A[0], k, debug)\n",
    "    return A[0][:, indices], B[0][:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def ETree(p_train_feature,p_train_label,p_test_feature,p_test_label,p_seed):\n",
    "    clf = ExtraTreesClassifier(n_estimators=50, random_state=p_seed)\n",
    "    \n",
    "    # Training\n",
    "    clf.fit(p_train_feature, p_train_label)\n",
    "    \n",
    "    # Training accuracy\n",
    "    print('Training accuracy：',clf.score(p_train_feature, np.array(p_train_label)))\n",
    "    print('Training accuracy：',accuracy_score(np.array(p_train_label),clf.predict(p_train_feature)))\n",
    "    #print('Training accuracy：',np.sum(clf.predict(p_train_feature)==np.array(p_train_label))/p_train_label.shape[0])\n",
    "\n",
    "    # Testing accuracy\n",
    "    print('Testing accuracy：',clf.score(p_test_feature, np.array(p_test_label)))\n",
    "    print('Testing accuracy：',accuracy_score(np.array(p_test_label),clf.predict(p_test_feature)))\n",
    "    #print('Testing accuracy：',np.sum(clf.predict(p_test_feature)==np.array(p_test_label))/p_test_label.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of C_train_x: (81, 5966)\n",
      "Shape of C_train_y: (81,)\n",
      "Shape of C_test_x: (21, 5966)\n",
      "Shape of C_test_y: (21,)\n"
     ]
    }
   ],
   "source": [
    "data_path=\"./Dataset/Prostate_GE.mat\"\n",
    "Data = scipy.io.loadmat(data_path)\n",
    "\n",
    "data_arr=Data['X']\n",
    "label_arr=Data['Y'][:, 0]-1\n",
    "\n",
    "Data=MinMaxScaler(feature_range=(0,1)).fit_transform(data_arr)\n",
    "\n",
    "C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(Data,label_arr,test_size=0.2,random_state=seed)\n",
    "\n",
    "print('Shape of C_train_x: ' + str(C_train_x.shape)) \n",
    "print('Shape of C_train_y: ' + str(C_train_y.shape)) \n",
    "print('Shape of C_test_x: ' + str(C_test_x.shape)) \n",
    "print('Shape of C_test_y: ' + str(C_test_y.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train=(C_train_x,C_train_x)\n",
    "test=(C_test_x,C_test_x)\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "C_train_selected_x, C_test_selected_x = pfa_transform(train, test,  key_feture_number)\n",
    "\n",
    "time_cost=time.clock() - start\n",
    "\n",
    "write_to_csv(np.array([time_cost]),\"./log/PFA_time\"+str(key_feture_number)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_feature: (81, 5966)\n",
      "Shape of train_label: (81,)\n",
      "Shape of test_feature: (21, 5966)\n",
      "Shape of test_label: (21,)\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9523809523809523\n",
      "Testing accuracy： 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "train_feature=C_train_x\n",
    "train_label=C_train_y\n",
    "test_feature=C_test_x\n",
    "test_label=C_test_y\n",
    "\n",
    "print('Shape of train_feature: ' + str(train_feature.shape)) \n",
    "print('Shape of train_label: ' + str(train_label.shape)) \n",
    "print('Shape of test_feature: ' + str(test_feature.shape)) \n",
    "print('Shape of test_label: ' + str(test_label.shape)) \n",
    "\n",
    "p_seed=seed\n",
    "ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_feature: (81, 64)\n",
      "Shape of train_label: (81,)\n",
      "Shape of test_feature: (21, 64)\n",
      "Shape of test_label: (21,)\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9047619047619048\n",
      "Testing accuracy： 0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "train_feature=C_train_selected_x\n",
    "train_label=C_train_y\n",
    "\n",
    "test_feature=C_test_selected_x\n",
    "test_label=C_test_y\n",
    "\n",
    "print('Shape of train_feature: ' + str(train_feature.shape)) \n",
    "print('Shape of train_label: ' + str(train_label.shape)) \n",
    "print('Shape of test_feature: ' + str(test_feature.shape)) \n",
    "print('Shape of test_label: ' + str(test_label.shape)) \n",
    "\n",
    "p_seed=seed\n",
    "ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18045226674357112\n"
     ]
    }
   ],
   "source": [
    "train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
